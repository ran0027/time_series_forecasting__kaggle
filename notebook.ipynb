{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba86fdbd",
   "metadata": {},
   "source": [
    "The purpose of this notebook was to practice using time series forecasting with neural networks.\n",
    "\n",
    "Unfortunately, using a neural network was not an effective method for forecasting with this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cb1ceb",
   "metadata": {},
   "source": [
    "This is a [Kaggle dataset / competition](https://www.kaggle.com/datasets/kannanaikkal/food-demand-forecasting).\n",
    "\n",
    "We have 145 weeks worth of order data for a meal delivery service with 77 centers and 51 unique meal offerings. The goal is to forecast how many of each type of meal each center will order in the next 10 weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f986c",
   "metadata": {},
   "source": [
    "First, import some standard libraries (including the ZipFile class from zipfile, for extracting data from a file within a zip archive.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d0550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f61b5b",
   "metadata": {},
   "source": [
    "Next, load the data as a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b9ba84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>week</th>\n",
       "      <th>center_id</th>\n",
       "      <th>meal_id</th>\n",
       "      <th>checkout_price</th>\n",
       "      <th>base_price</th>\n",
       "      <th>emailer_for_promotion</th>\n",
       "      <th>homepage_featured</th>\n",
       "      <th>num_orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1379560</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>1885</td>\n",
       "      <td>136.83</td>\n",
       "      <td>152.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1466964</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>1993</td>\n",
       "      <td>136.83</td>\n",
       "      <td>135.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1346989</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>2539</td>\n",
       "      <td>134.86</td>\n",
       "      <td>135.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338232</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>2139</td>\n",
       "      <td>339.50</td>\n",
       "      <td>437.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1448490</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>2631</td>\n",
       "      <td>243.50</td>\n",
       "      <td>242.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  week  center_id  meal_id  checkout_price  base_price  \\\n",
       "0  1379560     1         55     1885          136.83      152.29   \n",
       "1  1466964     1         55     1993          136.83      135.83   \n",
       "2  1346989     1         55     2539          134.86      135.86   \n",
       "3  1338232     1         55     2139          339.50      437.53   \n",
       "4  1448490     1         55     2631          243.50      242.50   \n",
       "\n",
       "   emailer_for_promotion  homepage_featured  num_orders  \n",
       "0                      0                  0         177  \n",
       "1                      0                  0         270  \n",
       "2                      0                  0         189  \n",
       "3                      0                  0          54  \n",
       "4                      0                  0          40  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with ZipFile('Data/meal_delivery_archive.zip') as zipArchive:\n",
    "    with zipArchive.open('train.csv') as f:\n",
    "        raw = pd.read_csv(f)\n",
    "        \n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a9cb6",
   "metadata": {},
   "source": [
    "First, let's check how many meal delivery centers are in the dataset (represented by center_id) and how many unique meals are served."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49633ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw.center_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e81b85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw.meal_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9404f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw.week.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbb962f",
   "metadata": {},
   "source": [
    "There are 77 centers, 51 meals and 145 weeks in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a80c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw.loc[:, ['week', 'center_id', 'meal_id', 'num_orders']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b08f041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>center_id</th>\n",
       "      <th>meal_id</th>\n",
       "      <th>num_orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>1885</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>1993</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>2539</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>2139</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>2631</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week  center_id  meal_id  num_orders\n",
       "0     1         55     1885         177\n",
       "1     1         55     1993         270\n",
       "2     1         55     2539         189\n",
       "3     1         55     2139          54\n",
       "4     1         55     2631          40"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884fdb66",
   "metadata": {},
   "source": [
    "When preparing the data for modeling with an LSTM (long short-term memory) neural network in Keras, it is important that we have a consistent order to the values for \"num_orders\" with no gaps. For example, if center 12 didn't order any of meal 1198 in week 3, we need to have a \"num_orders\" value of 0 at that index, not a missing row.\n",
    "\n",
    "The below cells build a new Pandas series using data from the training data, grouped by week, center id and meal id, and a list of expected indices that includes all combinations of week, center id and meal id, in order, to build such a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1706d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data.groupby(['week', 'center_id', 'meal_id']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2843d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>num_orders</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <th>center_id</th>\n",
       "      <th>meal_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">10</th>\n",
       "      <th>1062</th>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>2672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">145</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">186</th>\n",
       "      <th>2704</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456548 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        num_orders\n",
       "week center_id meal_id            \n",
       "1    10        1062            865\n",
       "               1109           2672\n",
       "               1198            269\n",
       "               1207            769\n",
       "               1216             54\n",
       "...                            ...\n",
       "145  186       2704             67\n",
       "               2707            175\n",
       "               2760             96\n",
       "               2826            162\n",
       "               2867             28\n",
       "\n",
       "[456548 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb85e9",
   "metadata": {},
   "source": [
    "Here, I am building the index for a series with every combination of week number, center id and meal id (in tuple form, in order) as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "175121af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⏰ this cell may take seconds to run\n",
    "%%time\n",
    "\n",
    "expected_indices = []\n",
    "\n",
    "for week_no in range(1, 146):\n",
    "    for center_id in sorted(data.center_id.unique()):\n",
    "        for meal_id in sorted(data.meal_id.unique()):\n",
    "            expected_indices.append((week_no, center_id, meal_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40078c08",
   "metadata": {},
   "source": [
    "Then, I am iterating over every (week, center_id, meal_id) tuple in the expected index and filling in the number of orders from the dataset, if it is given, and otherwise, assuming that there were 0 orders for that meal to that center for that week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ff25ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.7 s, sys: 160 ms, total: 19.9 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "# ⏰ this cell may take 20 seconds to run\n",
    "filled_in_values = []\n",
    "\n",
    "for index in expected_indices:\n",
    "    try:\n",
    "        num_orders = grouped_data.loc[index, 'num_orders']\n",
    "    except:\n",
    "        num_orders = 0\n",
    "    filled_in_values.append(num_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69132c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 1062)        865\n",
       "(1, 10, 1109)       2672\n",
       "(1, 10, 1198)        269\n",
       "(1, 10, 1207)        769\n",
       "(1, 10, 1216)         54\n",
       "                    ... \n",
       "(145, 186, 2707)     175\n",
       "(145, 186, 2760)      96\n",
       "(145, 186, 2826)     162\n",
       "(145, 186, 2867)      28\n",
       "(145, 186, 2956)       0\n",
       "Name: num_orders, Length: 569415, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(filled_in_values, index=expected_indices, name='num_orders')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad6fde",
   "metadata": {},
   "source": [
    "The next step in preparing the data for modeling is to put it into the three-dimensional numpy array format expected by a Keras LSTM.\n",
    "\n",
    "The expected  shape is (sample_size, window_size, num_features) where window_size refers to how far back the model looks when making its prediction for the next week.\n",
    "\n",
    "So, for example, if we select a window_size of 5, our input array will look something like this:  \n",
    "\n",
    "\\[ \\[ list of week 1 orders \\], \\[ list of week 2 orders \\], ..., \\[ list of week 5 orders \\] \\]\n",
    "    \n",
    "And the corresponding output will be the list of week 6 orders:\n",
    "\n",
    "\\[ list of week 6 orders \\]\n",
    "\n",
    "Note that each `list of week i orders` is extraordinarily long: there are 77 centers and 51 meals that can be ordered by each center, so there are $77*51$ values for `num_orders` in a given week. These are in a predictable order due to our data preprocessing, so the model can learn the relationship for each center and meal combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600b094e",
   "metadata": {},
   "source": [
    "The code below iterates over the number of training examples with a given window size, and uses the \"filled_in_values\" list which gives the number of orders for each week, center-id and meal_id *in order* to create the numpy arrays for X and y specified above.\n",
    "\n",
    "Depending on the window size, we will need to create a different input array, so specify that initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91ee3016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 5, 3927) (140, 3927)\n"
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "\n",
    "# constant for this dataset:\n",
    "num_center_meal_combos = 77*51\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for i in range(1, 146-window_size):\n",
    "    window = []\n",
    "    for week_no in range(i, i + window_size):\n",
    "        window_start = (week_no - 1)*num_center_meal_combos\n",
    "        window_stop = week_no*num_center_meal_combos\n",
    "        window.append(filled_in_values[window_start:window_stop])\n",
    "    X.append(window)\n",
    "    label_stop = (week_no + 1)*num_center_meal_combos\n",
    "    label = filled_in_values[window_stop:label_stop]\n",
    "    y.append(label)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20865792",
   "metadata": {},
   "source": [
    "Check results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a00724d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 865, 2672,  269,  769,   54,  324,   53,  177,  595,   95],\n",
       "        [ 782, 1864,  136,  458,   94,  458,   67,  285,  458,   81],\n",
       "        [ 851, 1161,  418,  418,   96,  337,   27,  756,  445,   40],\n",
       "        [1202, 1376,  243,  459,  230,  393,   69,  339,  366,   41],\n",
       "        [ 958, 1511,  150,  312,  189,  162,   26,  501,  432,   15]],\n",
       "\n",
       "       [[ 782, 1864,  136,  458,   94,  458,   67,  285,  458,   81],\n",
       "        [ 851, 1161,  418,  418,   96,  337,   27,  756,  445,   40],\n",
       "        [1202, 1376,  243,  459,  230,  393,   69,  339,  366,   41],\n",
       "        [ 958, 1511,  150,  312,  189,  162,   26,  501,  432,   15],\n",
       "        [1094, 2105,  176,  296,  148,   80,   82,   69,  743,   53]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2, :, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f813c300",
   "metadata": {},
   "source": [
    "The array above shows us the first two \"windows\" of our time series data, where each sub-list is a single time step (and, as such, we have 5 such lists with a window size of 5), and we see the number of orders for the first 10 meal-center combinations.\n",
    "\n",
    "In the output array, we should see the corresponding *next* week of orders for the first 10 meal-center combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3284be7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1094, 2105,  176,  296,  148,   80,   82,   69,  743,   53],\n",
       "       [1513, 1916,  405,  150,  149,  148,   15,   55,  431,   53]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:2, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233de68",
   "metadata": {},
   "source": [
    "Now let's split the data into training and validation data. (There is a separate file with \"test\" data that we can use as a holdout test set.)\n",
    "\n",
    "Because our goal is to predict 10 weeks out on the test set (the data in \"test.csv\"), let's use the last 10 weeks of \"train.csv\" data as validation data. To truly evaluate our model's performance, we would incorporate each new data point as training data after we test the model's prediction on that time step, but making predictions for all 10 time-steps at once without re-training will suffice initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccd2b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = X[:-10], X[-10:], y[:-10], y[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5f91cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 5, 3927) (10, 5, 3927) (130, 3927) (10, 3927)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79644c8b",
   "metadata": {},
   "source": [
    "Now, we can build a predictive model.\n",
    "\n",
    "Import the necessary libraries and packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf02f05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 13:19:27.485296: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed6acc",
   "metadata": {},
   "source": [
    "I want to use an LSTM layer, and I don't want the LSTM cell state to reset automatically after each batch, so I am going to do the following:\n",
    "\n",
    "- Specify `stateful=True` in the initialization of the LSTM layer\n",
    "- This forces me to specify the batch size at the initialization of the LSTM layer also (choose batch size of 10, which divides evenly into training and validation data sample size)\n",
    "- Manually run however many epochs & reset the cell state at the end of each one\n",
    "- Manually log training and validation loss & accuracy at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a0338e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 13:19:34.159397: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# specify batch size (for lstm layer), the width of the lstm layer and output size (centers*meals)\n",
    "batch_size = 10\n",
    "lstm_width = 20\n",
    "output_size = y.shape[-1]\n",
    "\n",
    "# specify network architecture: Sequential, with one LSTM stateful layer & one Dense layer with linear activation\n",
    "baseline_model = Sequential()\n",
    "baseline_model.add(LSTM(lstm_width,\n",
    "                        activation='relu',\n",
    "                        batch_input_shape=(batch_size, window_size, output_size),\n",
    "                        stateful=True))\n",
    "baseline_model.add(Dense(output_size))\n",
    "\n",
    "# compile the model\n",
    "baseline_model.compile(loss='mean_absolute_percentage_error', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1b8926e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 18ms/step - loss: 2890182656.0000 - acc: 0.0000e+00 - val_loss: 833764032.0000 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1247804.1250 - acc: 0.0000e+00 - val_loss: 567510.0000 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 365868.7812 - acc: 0.0000e+00 - val_loss: 236303.1562 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 173332.2344 - acc: 0.0000e+00 - val_loss: 127748.5469 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 83737.9922 - acc: 0.0000e+00 - val_loss: 94248.0156 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train\n",
    "num_epochs = 5\n",
    "\n",
    "# record history from each epoch\n",
    "history = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "# manually train for num_epochs epochs\n",
    "for i in range(num_epochs):\n",
    "    baseline_model.fit(X_train,\n",
    "                       y_train,\n",
    "                       batch_size=batch_size,\n",
    "                       validation_data=(X_val, y_val),\n",
    "                       validation_batch_size=batch_size,\n",
    "                       epochs=1)\n",
    "    # record loss and accuracy for training and val this epoch\n",
    "    for key in baseline_model.history.history.keys():\n",
    "        history[key].append(baseline_model.history.history[key])\n",
    "    # reset LSTM cell state\n",
    "    baseline_model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb7d33b",
   "metadata": {},
   "source": [
    "Loss does decrease (for the training and validation sets) but it there is still virtually no accuracy by the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65801073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 51193.0117 - acc: 0.0000e+00 - val_loss: 87478.1953 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39981.6758 - acc: 0.0000e+00 - val_loss: 94546.0391 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38069.2578 - acc: 0.0000e+00 - val_loss: 102224.4609 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35999.9219 - acc: 0.0000e+00 - val_loss: 112142.3750 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37033.7383 - acc: 0.0000e+00 - val_loss: 120704.3750 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38461.5703 - acc: 0.0000e+00 - val_loss: 128843.4375 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37788.1992 - acc: 0.0000e+00 - val_loss: 138545.5938 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37028.7031 - acc: 0.0000e+00 - val_loss: 146301.2500 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37206.9922 - acc: 0.0000e+00 - val_loss: 155408.0312 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39343.0977 - acc: 0.0000e+00 - val_loss: 164995.5938 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37398.2852 - acc: 0.0000e+00 - val_loss: 175091.3906 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35756.4141 - acc: 0.0000e+00 - val_loss: 183208.0312 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36850.6992 - acc: 0.0000e+00 - val_loss: 191607.9688 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36244.7773 - acc: 0.0000e+00 - val_loss: 200433.3750 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35672.7773 - acc: 0.0000e+00 - val_loss: 210246.2188 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36589.1641 - acc: 0.0000e+00 - val_loss: 217985.5000 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37408.8828 - acc: 0.0000e+00 - val_loss: 229692.0938 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36663.4570 - acc: 0.0000e+00 - val_loss: 237345.0312 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35751.2266 - acc: 0.0000e+00 - val_loss: 246758.3438 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35730.8320 - acc: 0.0000e+00 - val_loss: 252149.0000 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train\n",
    "num_epochs = 20\n",
    "\n",
    "# record history from each epoch\n",
    "history = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "# manually train for num_epochs epochs\n",
    "for i in range(num_epochs):\n",
    "    baseline_model.fit(X_train,\n",
    "                       y_train,\n",
    "                       batch_size=batch_size,\n",
    "                       validation_data=(X_val, y_val),\n",
    "                       validation_batch_size=batch_size,\n",
    "                       epochs=1)\n",
    "    # record loss and accuracy for training and val this epoch\n",
    "    for key in baseline_model.history.history.keys():\n",
    "        history[key].append(baseline_model.history.history[key])\n",
    "    # reset LSTM cell state\n",
    "    baseline_model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598c123a",
   "metadata": {},
   "source": [
    "Let's try:\n",
    "\n",
    "- different window sizes\n",
    "- different widths for the lstm layer\n",
    "- an additional hidden layer with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e20c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_model(lstm_width, batch_size):\n",
    "    global output_size\n",
    "    global window_size\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_width,\n",
    "                   activation='relu',\n",
    "                   batch_input_shape=(batch_size, window_size, output_size),\n",
    "                   stateful=True))\n",
    "    model.add(Dense(output_size))\n",
    "    model.compile(loss='mean_absolute_percentage_error', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d41345e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wider_model = get_lstm_model(40, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7bded7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, num_epochs, batch_size):\n",
    "    # record history from each epoch\n",
    "    history = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  validation_data=(X_val, y_val),\n",
    "                  validation_batch_size=batch_size,\n",
    "                  epochs=1)\n",
    "        # record loss and accuracy for training and val this epoch\n",
    "        for key in model.history.history.keys():\n",
    "            history[key].append(model.history.history[key])\n",
    "        # reset LSTM cell state\n",
    "        model.reset_states()\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd3c5b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 40593.0117 - acc: 0.0000e+00 - val_loss: 138426.1875 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 39387.3086 - acc: 0.0000e+00 - val_loss: 149070.8750 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 38937.9375 - acc: 0.0000e+00 - val_loss: 156552.4844 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 36698.0820 - acc: 0.0000e+00 - val_loss: 164646.5312 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 36914.7461 - acc: 0.0000e+00 - val_loss: 173977.7188 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 36805.3008 - acc: 0.0000e+00 - val_loss: 183878.8438 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 37378.5430 - acc: 0.0000e+00 - val_loss: 191033.6562 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 39494.0781 - acc: 0.0000e+00 - val_loss: 201626.7031 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 38634.3477 - acc: 0.0000e+00 - val_loss: 210134.9531 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 37520.7969 - acc: 0.0000e+00 - val_loss: 220474.2031 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = train_and_evaluate(wider_model, num_epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58bed0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 5, 3927)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c159905d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3927"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f8a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_model(lstm_width, batch_size):\n",
    "    global output_size\n",
    "    global window_size\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_width,\n",
    "                   activation='relu',\n",
    "                   batch_input_shape=(batch_size, window_size, output_size),\n",
    "                   stateful=True))\n",
    "    model.add(Dense(output_size))\n",
    "    model.compile(loss='mean_absolute_percentage_error', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d7e5435",
   "metadata": {},
   "outputs": [],
   "source": [
    "much_wider_model = get_lstm_model(3927, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c6982fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 17s 1s/step - loss: 13145552715776.0000 - acc: 0.0000e+00 - val_loss: 14558699716608.0000 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 16s 1s/step - loss: 6144391118848.0000 - acc: 0.0000e+00 - val_loss: 8848591028224.0000 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 15s 1s/step - loss: 3090220843008.0000 - acc: 0.0000e+00 - val_loss: 3462987513856.0000 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 15s 1s/step - loss: 1843857588224.0000 - acc: 0.0000e+00 - val_loss: 1790708023296.0000 - val_acc: 0.0000e+00\n",
      "13/13 [==============================] - 15s 1s/step - loss: 967498989568.0000 - acc: 0.0000e+00 - val_loss: 633986875392.0000 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = train_and_evaluate(much_wider_model, num_epochs=5, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdae3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeper_model = Sequential()\n",
    "deeper_model.add(LSTM(3927,\n",
    "                      activation='relu',\n",
    "                      batch_input_shape=(batch_size, window_size, output_size),\n",
    "                      stateful=True))\n",
    "deeper_model.add(Dense(3927))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nn)",
   "language": "python",
   "name": "nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
